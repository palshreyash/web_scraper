{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scraping-github-topics\n",
    "\n",
    " - Web scraping is the process of using bots to extract content and data from a website. Unlike screen scraping, which only copies pixels displayed onscreen, web scraping extracts underlying HTML code and, with it, data stored in a database.\n",
    " - GitHub is a web-based version-control and collaboration platform for software developers. GitHub facilitates social coding by providing a web interface to the Git code repository and management tools for collaboration. GitHub can be thought of as a serious social networking site for software developers.\n",
    " - We'll be using python to code the project, requests library to download the web pages, beautiful soup to parse the downloaded info and pandas library to store the extracted info in the form of a data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROJECT OUTLINE\n",
    "\n",
    "- We're going to scrape https://github.com/topics\n",
    "- We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n",
    "- For each topic, we'll get the top 25 repositories in the topic from the topic page\n",
    "- For each repository, we'll grab the repo name, username, stars and repo URL\n",
    "- For each topic we'll create a CSV file in the following format:\n",
    "\n",
    "Repo Name,Username,Stars,Repo URL\n",
    "three.js,mrdoob,69700,https://github.com/mrdoob/three.js\n",
    "libgdx,libgdx,18300,https://github.com/libgdx/libgdx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRAPE THE LIST OF TOPICS FROM GITHUB\n",
    "\n",
    "- Use requests to download the page\n",
    "- Use beautiful soup 4 to parse and extract information\n",
    "- convert to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet\n",
    "!pip install beautifulsoup4 --upgrade --quiet\n",
    "!pip install requests --upgrade --quiet\n",
    "!pip install pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovianimport requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_page():\n",
    "    topic_url = 'https://github.com/topics'\n",
    "    response = requests.get(topic_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page{}'.format(topic_url))\n",
    "        scrape_topics_repos()\n",
    "    doc = BeautifulSoup(response.text,'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_descs(doc):\n",
    "    desc_selector = 'f5 color-text-secondary mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
    "    topic_descs = []\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "    return topic_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_urls(doc):\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'd-flex no-underline'})\n",
    "    topic_urls = []\n",
    "    base_url = 'https://github.com'\n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def scrape_topics(topics_url):\n",
    "    #topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topics_url))\n",
    "        scrape_topics_repos()\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    topics_dict = {\n",
    "        'title': get_topic_titles(doc),\n",
    "        'description': get_topic_descs(doc),\n",
    "        'url': get_topic_urls(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    # Download the page\n",
    "    response = requests.get(topic_url)\n",
    "    # Check successful response\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "        scrape_topics_repos()\n",
    "    # Parse using Beautiful soup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(h1_tag, star_tag):\n",
    "    # returns all the required info about a repository\n",
    "    a_tags = h1_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url =  base_url + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_repos(topic_doc):\n",
    "    # Get the h1 tags containing repo title, repo URL and username\n",
    "    h1_selection_class = 'f3 color-text-secondary text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.find_all('h1', {'class': h1_selection_class} )\n",
    "    # Get star tags\n",
    "    star_tags = topic_doc.find_all('a', { 'class': 'social-count float-none'})\n",
    "    \n",
    "    topic_repos_dict = { 'username': [], 'repo_name': [], 'stars': [],'repo_url': []}\n",
    "\n",
    "    # Get repo info\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "        \n",
    "    return pd.DataFrame(topic_repos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic(topic_url,path):\n",
    "    if os.path.exists(path):\n",
    "        print('the file {} already exists. Skipping ...'.format(path))\n",
    "        return \n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    for i in range(1,15):\n",
    "        topics_url = 'https://github.com/topics?page={}'.format(i)\n",
    "        topics_df = scrape_topics(topics_url)\n",
    "    \n",
    "        os.makedirs('data', exist_ok=True)\n",
    "        for index, row in topics_df.iterrows():\n",
    "            print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
    "            scrape_topic(row['url'], 'data/{}.csv'.format(row['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics\n",
      "Scraping top repositories for \"3D\"\n",
      "the file data/3D.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Ajax\"\n",
      "the file data/Ajax.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Algorithm\"\n",
      "the file data/Algorithm.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Amp\"\n",
      "the file data/Amp.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Android\"\n",
      "the file data/Android.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Angular\"\n",
      "the file data/Angular.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Ansible\"\n",
      "the file data/Ansible.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"API\"\n",
      "the file data/API.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Arduino\"\n",
      "the file data/Arduino.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"ASP.NET\"\n",
      "the file data/ASP.NET.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Atom\"\n",
      "the file data/Atom.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Awesome Lists\"\n",
      "the file data/Awesome Lists.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Amazon Web Services\"\n",
      "the file data/Amazon Web Services.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Azure\"\n",
      "the file data/Azure.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Babel\"\n",
      "the file data/Babel.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Bash\"\n",
      "the file data/Bash.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Bitcoin\"\n",
      "the file data/Bitcoin.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Bootstrap\"\n",
      "the file data/Bootstrap.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Bot\"\n",
      "the file data/Bot.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"C\"\n",
      "the file data/C.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Chrome\"\n",
      "the file data/Chrome.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Chrome extension\"\n",
      "the file data/Chrome extension.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Command line interface\"\n",
      "the file data/Command line interface.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Clojure\"\n",
      "the file data/Clojure.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Code quality\"\n",
      "the file data/Code quality.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Code review\"\n",
      "the file data/Code review.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Compiler\"\n",
      "the file data/Compiler.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Continuous integration\"\n",
      "the file data/Continuous integration.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"COVID-19\"\n",
      "the file data/COVID-19.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"C++\"\n",
      "the file data/C++.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Cryptocurrency\"\n",
      "the file data/Cryptocurrency.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Crystal\"\n",
      "the file data/Crystal.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"C#\"\n",
      "the file data/C#.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"CSS\"\n",
      "the file data/CSS.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Data structures\"\n",
      "the file data/Data structures.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Data visualization\"\n",
      "the file data/Data visualization.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Database\"\n",
      "the file data/Database.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Deep learning\"\n",
      "the file data/Deep learning.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Dependency management\"\n",
      "the file data/Dependency management.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Deployment\"\n",
      "the file data/Deployment.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Django\"\n",
      "the file data/Django.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Docker\"\n",
      "the file data/Docker.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Documentation\"\n",
      "the file data/Documentation.csv already exists. Skipping ...\n",
      "Scraping top repositories for \".NET\"\n",
      "the file data/.NET.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Electron\"\n",
      "the file data/Electron.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Elixir\"\n",
      "the file data/Elixir.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Emacs\"\n",
      "the file data/Emacs.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Ember\"\n",
      "the file data/Ember.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Emoji\"\n",
      "the file data/Emoji.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Emulator\"\n",
      "the file data/Emulator.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"ESLint\"\n",
      "the file data/ESLint.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Ethereum\"\n",
      "the file data/Ethereum.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Express\"\n",
      "the file data/Express.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Firebase\"\n",
      "the file data/Firebase.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Firefox\"\n",
      "the file data/Firefox.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Flask\"\n",
      "the file data/Flask.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Font\"\n",
      "the file data/Font.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Framework\"\n",
      "the file data/Framework.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Front end\"\n",
      "the file data/Front end.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Game engine\"\n",
      "the file data/Game engine.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Git\"\n",
      "the file data/Git.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"GitHub API\"\n",
      "the file data/GitHub API.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Go\"\n",
      "the file data/Go.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Google\"\n",
      "the file data/Google.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Gradle\"\n",
      "the file data/Gradle.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"GraphQL\"\n",
      "the file data/GraphQL.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Gulp\"\n",
      "the file data/Gulp.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Hacktoberfest\"\n",
      "the file data/Hacktoberfest.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Haskell\"\n",
      "the file data/Haskell.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Homebrew\"\n",
      "the file data/Homebrew.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Homebridge\"\n",
      "the file data/Homebridge.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"HTML\"\n",
      "the file data/HTML.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"HTTP\"\n",
      "the file data/HTTP.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Icon font\"\n",
      "the file data/Icon font.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"iOS\"\n",
      "the file data/iOS.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"IPFS\"\n",
      "the file data/IPFS.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Java\"\n",
      "the file data/Java.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"JavaScript\"\n",
      "the file data/JavaScript.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Jekyll\"\n",
      "the file data/Jekyll.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"jQuery\"\n",
      "the file data/jQuery.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"JSON\"\n",
      "the file data/JSON.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"The Julia Language\"\n",
      "the file data/The Julia Language.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Jupyter Notebook\"\n",
      "the file data/Jupyter Notebook.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Koa\"\n",
      "the file data/Koa.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Kotlin\"\n",
      "the file data/Kotlin.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Kubernetes\"\n",
      "the file data/Kubernetes.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Laravel\"\n",
      "the file data/Laravel.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"LaTeX\"\n",
      "the file data/LaTeX.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Library\"\n",
      "the file data/Library.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Linux\"\n",
      "the file data/Linux.csv already exists. Skipping ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping top repositories for \"Localization\"\n",
      "the file data/Localization.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Lua\"\n",
      "the file data/Lua.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Machine learning\"\n",
      "the file data/Machine learning.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"macOS\"\n",
      "the file data/macOS.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Markdown\"\n",
      "the file data/Markdown.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Mastodon\"\n",
      "the file data/Mastodon.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Material design\"\n",
      "the file data/Material design.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"MATLAB\"\n",
      "the file data/MATLAB.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Maven\"\n",
      "the file data/Maven.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Minecraft\"\n",
      "the file data/Minecraft.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Mobile\"\n",
      "the file data/Mobile.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Monero\"\n",
      "the file data/Monero.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"MongoDB\"\n",
      "the file data/MongoDB.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Mongoose\"\n",
      "the file data/Mongoose.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Monitoring\"\n",
      "the file data/Monitoring.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"MvvmCross\"\n",
      "the file data/MvvmCross.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"MySQL\"\n",
      "the file data/MySQL.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"NativeScript\"\n",
      "the file data/NativeScript.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Nim\"\n",
      "the file data/Nim.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Natural language processing\"\n",
      "the file data/Natural language processing.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Node.js\"\n",
      "the file data/Node.js.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"NoSQL\"\n",
      "the file data/NoSQL.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"npm\"\n",
      "the file data/npm.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Objective-C\"\n",
      "the file data/Objective-C.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"OpenGL\"\n",
      "the file data/OpenGL.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Operating system\"\n",
      "the file data/Operating system.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"P2P\"\n",
      "the file data/P2P.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Package manager\"\n",
      "the file data/Package manager.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Parsing\"\n",
      "the file data/Parsing.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Perl\"\n",
      "the file data/Perl.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Phaser\"\n",
      "the file data/Phaser.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"PHP\"\n",
      "the file data/PHP.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"PICO-8\"\n",
      "the file data/PICO-8.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Pixel Art\"\n",
      "the file data/Pixel Art.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"PostgreSQL\"\n",
      "the file data/PostgreSQL.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Project management\"\n",
      "the file data/Project management.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Publishing\"\n",
      "the file data/Publishing.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"PWA\"\n",
      "the file data/PWA.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Python\"\n",
      "the file data/Python.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Qt\"\n",
      "the file data/Qt.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"R\"\n",
      "the file data/R.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Rails\"\n",
      "the file data/Rails.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Raspberry Pi\"\n",
      "the file data/Raspberry Pi.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Ratchet\"\n",
      "the file data/Ratchet.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"React\"\n",
      "the file data/React.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"React Native\"\n",
      "the file data/React Native.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"ReactiveUI\"\n",
      "the file data/ReactiveUI.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Redux\"\n",
      "the file data/Redux.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"REST API\"\n",
      "the file data/REST API.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Ruby\"\n",
      "the file data/Ruby.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Rust\"\n",
      "the file data/Rust.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Sass\"\n",
      "the file data/Sass.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Scala\"\n",
      "the file data/Scala.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"scikit-learn\"\n",
      "the file data/scikit-learn.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Software-defined networking\"\n",
      "the file data/Software-defined networking.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Security\"\n",
      "the file data/Security.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Server\"\n",
      "the file data/Server.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Serverless\"\n",
      "the file data/Serverless.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Shell\"\n",
      "the file data/Shell.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Sketch\"\n",
      "the file data/Sketch.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"SpaceVim\"\n",
      "the file data/SpaceVim.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Spring Boot\"\n",
      "the file data/Spring Boot.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"SQL\"\n",
      "the file data/SQL.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Storybook\"\n",
      "the file data/Storybook.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Support\"\n",
      "the file data/Support.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Swift\"\n",
      "the file data/Swift.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Symfony\"\n",
      "the file data/Symfony.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Telegram\"\n",
      "the file data/Telegram.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Tensorflow\"\n",
      "the file data/Tensorflow.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Terminal\"\n",
      "the file data/Terminal.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Terraform\"\n",
      "the file data/Terraform.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Testing\"\n",
      "the file data/Testing.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Twitter\"\n",
      "the file data/Twitter.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"TypeScript\"\n",
      "the file data/TypeScript.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Ubuntu\"\n",
      "the file data/Ubuntu.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Unity\"\n",
      "the file data/Unity.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Unreal Engine\"\n",
      "the file data/Unreal Engine.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Vagrant\"\n",
      "the file data/Vagrant.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Vim\"\n",
      "the file data/Vim.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Virtual reality\"\n",
      "the file data/Virtual reality.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Vue.js\"\n",
      "the file data/Vue.js.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Wagtail\"\n",
      "the file data/Wagtail.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Web Components\"\n",
      "the file data/Web Components.csv already exists. Skipping ...\n",
      "Scraping top repositories for \"Web app\"\n",
      "Scraping top repositories for \"Webpack\"\n",
      "Scraping top repositories for \"Windows\"\n",
      "Scraping top repositories for \"WordPlate\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping top repositories for \"WordPress\"\n",
      "Scraping top repositories for \"Xamarin\"\n",
      "Scraping top repositories for \"XML\"\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"shreyash075/scraping-github-topics\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/shreyash075/scraping-github-topics\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/shreyash075/scraping-github-topics'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}